{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Persiapan Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Sample Dataset : Iris Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = load_iris()\n",
    "\n",
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Salah satu frase yang paling krusial dalam machine workflow adalah persiapan dataset. Ketika kita bekerja dengan real data di lapangan,fase ini membutuhkan paling banyak waktu dan effort. Dalam kasus ini, mari kita coba menyederhankan prosesnya dengan memanfaatkan sample dataset yang sudah disediakan oleh sklearn.\n",
    "\n",
    "Setelah dataset pada code diatas kita load, selanjutnya kita akan membagi menjadi 2 bagian yang dikenal dengan istilah splitting dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting Dataset : Training & Testing Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=0.4,\n",
    "                                                    random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset diatas telah kami split dan menjadi 2 bagian yaitu training set dan testing set. SkLearn memfasilitasi kita dalam proses splitting, testing, dan training suatu dataset. Kita hanya mengimport modul dan memakai 4 parameter diatas, X sebagai parameter pertama adalah sekumpulan nilai features nya, Y sebagai parameter kedua adalah sekumpulan nilai targetnya, parameter ketiga yaitu test_size sebagai ukuran dari testing sizenya yang dalam hal ini adalah 0.4 yang berarti testing set kita akan memiliki proporsi 40% dari total keseluruhan dataset kita, sedangkan untuk training setnya akan menempati proporsi 60%. Selanjutnya untuk proses pengacakan kita gunakan random set number = 1. Train test split akan menghasilkan 4 kumpulan nilai yang harus ditampung kedalam 4 variable yaitu X_train, X_test, y_train, y_test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Model\n",
    "- Pada Scikit Learn, model machine learning dibentuk dari class yang dikenal dengan istilah estimator\n",
    "- Setiap estimator akan mengimplementasikan dua method utama, yaitu fit() dan predict()\n",
    "- Method fit() digunakan untuk melakukan training model\n",
    "- Method predict() digunakan untuk melakukan estimasi/prediksi dengan memanfaatkan trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kneighbors Classifier sebagai Machine Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=3)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "model = KNeighborsClassifier(n_neighbors=3)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code diatas adalah implementasi  dari kneighbors classifier yang didalamnya terdapat :\n",
    "- Import modul kneighbors.\n",
    "- Pembentukan objek dari class kneighbour yang membutuhkan satu buah parameter yaitu n_neighbour yang dibutuhkan karena objek model yang mau kita bentuk berasalah dari kneighbors classifier, dimana kita perlu memspesifikasikan jumlah neighbournya yang dalam kasus diatas bernilai = 3. Objek model yang terbentuk akan kita tampung dalam variabel model.\n",
    "- Selanjutnya variabel model ini akan kita training dengan menggunakan method fit, yang proses trainingnya akan memaanfaatkan training set. Oleh karenannya kita memanggil x_train (berisi sekumpulan features untuk training set) dan y_train (berisi sekumpulan nilai target untuk training set)\n",
    "- Ketika model menjalani proses training, maka model ini dikenal dengan istilah train model atau model yang sudah di training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluasi Model\n",
    "\n",
    "Testing set digunakan untuk melakukan proses evaluasi atau testing performa dari model yang ditraining sebelumnya."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9833333333333333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Terdapat beberapa metrics yang bisa kita gunakan untuk melakukan prose evaluasi, yang dalam kasus ini kita menggunakan accuracy sebagai metriksnya.\n",
    "- Pada code tersebut, sklearn sudah menyatakan sejumlah metriks untuk melakukan proses evaluasi dari sautu mode yang salah satunya adalah accuracy score.\n",
    "- Pertama kita perlu mengimport modul sesuai code diatas.\n",
    "- Selanjutnya, kita akan melakukan prediksi terhadap nilai features yang ada di dalam testing dataset.\n",
    "- Memanggil \"model.predict(X_test)\" yang ditampung dalam variabel y_pred.\n",
    "- Proses evaluasi ini pada dasarnya akan membandingkan nilai target yang terdapat dalam variable y_test dibandingkan dengan nilai prediksi yang ditampung kedalam y_pred.\n",
    "- Proses pengukuran bisa bermacam-macam, tetpai kali ini akan di demokan dengan menggunakan accuracy score yang ditampung ke dalam variable acc.\n",
    "- Dalam kasus ini accuracy yang didapatkan 0.9833333333333333 yang berarti nilai accuracy dari model ini adalah 98% (sangat baik)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pemanfaatan Trained Model\n",
    "\n",
    "Jika trained model dinilai cukup baik berdasarkan hasil evaluasi, maka model yang di training tersebut dapat digunakan untuk memprediksi data baru."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_baru = [[5, 5, 3, 2], #intance pertama \n",
    "             [2, 4, 3, 5]] #instace kedua\n",
    "\n",
    "preds =  model.predict(data_baru)\n",
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Berbeda dengan tetsing set, pada data baru kita hanya memiliki sekumpulan nilai features, tetapi tidak memiliki nilai target.\n",
    "- Pertama-tama kitaakan membentuk data set yang baru, dalam kasus ini dataset terdiri dari 2 instance atau row (baris) yang dimana setiap barisnya terbagi ke dalam 4 nilai features.\n",
    "- Kita akan melakukan prediksi dengan cara memanggil train model lalu panggil method predict yang dikenakan terhadap \"data_baru\"\n",
    "- Akan menghasilkan array([1, 2]) artinya untuk instace pertama dengan dimana baris pertama memiliki prediksi nilai target 1 dan baris kedua memiliki prediksi nilai target 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hasil Prediksi: ['versicolor', 'virginica']\n"
     ]
    }
   ],
   "source": [
    "pred_species = [iris.target_names[p] for p in preds] \n",
    "print(f'Hasil Prediksi: {pred_species}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selanjutnya, kita akan melakukan proses pemanggilan target_names yang kita mappingkan dengan nilai hasil prediksi tersebut. Disini kita bisa menyimpulkan bahwa, untuk data pertama dengan nilai features (5, 5, 3, 2) ini diprediksi termasuk ke dalam klasifikasi species iris versicolor, sedangkan nilai features (2, 4, 3, 5) ini diprediksi termasuk ke dalam klasifikasi species iris virginica."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dumping & Load Trained Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dumping Model Machine Learning menjadi file joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['iris_classifier_knn.joblib']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(model, 'iris_classifier_knn.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Untuk menggunakan joblib, kita harus mengimport joblibnya.\n",
    "- Setelah joblib diimport, maka kita bisa memulai melakukan proses dumping atau loading model machine learning.\n",
    "- Memanggil joblib.dump, proses ini memerlukan 2 parameter, parameter pertama adalah train model yang akan kita dump, parameter kedua adalah nama file joblibnya yang dalam kasus ini, di set sebagai 'iris_classifier_knn.joblib'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Model Machine Learning dari file joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "production_model = joblib.load('iris_classifier_knn.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Begitu file joblib tersebut di load, maka akan dihasilkan suatu machine learning model yang sudah kita trainining sebelumnya. Dalam kasus kali ini, machine learning model ditampung ke dalam sautu variable yaitu 'production_model'.\n",
    "- Selanjutnya, kita bisa memanfaatkan production model ini untuk melakukan prediksi terhadap data-data baru yang kita temui di production."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Untuk pembelajaran lebih lengkapnya jangan lupa untuk mengunjungi channel youtube indonesia belajar pada link \"https://www.youtube.com/watch?v=tiREcHrtDLo\"    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \"Banyak Belajar, Biar Bisa Bantu Banyak Orang\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
